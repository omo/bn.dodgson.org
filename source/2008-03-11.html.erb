---
title: "From Netflix leaderboard"
date: 2008-03-11
---
<h3>From Netflix leaderboard</h3>
<ul>
<li><a href="http://home.mit.bme.hu/~gtakacs/gravity">Team Bravity</a><ul>
<li><a href="http://www.sze.hu/~gtakacs/">Author のページ. 論文あり</a></li>
</ul></li>
<li><a href="http://www.research.att.com/~volinsky/netflix/">BellKor/KorBell</a>論文あり<ul>
<li><a href="http://public.research.att.com/~yehuda/pubs/BellKorIcdm07.pdf">論文のひとつ</a></li>
</ul></li>
<li><a href="http://www.djweiss.info/netflix.html">Team Dinosaur Planet</a> Gravity と連携したらしい. 論文はまだだけそのうち出るそうな.<ul>
<li><a href="http://tech.groups.yahoo.com/group/theory-edge/message/13153">Interview</a> SVD ってのは使わんといかんの？</li>
</ul></li>
<li><a href="http://www.tillberg.us/netflixprize">Dan Tillberg</a> いくつかのリンク<ul>
<li><a href="http://www.tillberg.us/netflixprizejumpstart">Netflix Prize Jumpstart Series</a> matrix factorization というは調べる必要がありそう. neral network はいいや...</li>
</ul></li>
<li><a href="http://justaguyinagarage.blogspot.com/">Just A Guy In A Garage</a></li>
<li><a href="http://www.cs.toronto.edu/~rsalakhu/mltoronto.html">ML@UToronto</a><ul>
<li><a href="http://www.cs.toronto.edu/~rsalakhu/mltoronto.html">Restricted Boltzmann Machines for Collaborative Filtering</a></li>
</ul></li>
<li><a href="http://www.mimuw.edu.pl/~paterek/">Arek Paterek</a><ul>
<li><a href="http://www.mimuw.edu.pl/~paterek/">Improving regularized singular value decomposition for collaborative filtering</a></li>
</ul></li>
</ul>
<p>うーん. KorBell はさすがに読んだ方がいいか. SVD とかも...
例の Bishop の本にも SVD の話は載ってるっぽい.</p>
<p>読むもの:</p>
<ul>
<li>&gt;SVD<ul>
<li><a href="http://en.wikipedia.org/wiki/Singular_value_decomposition">http://en.wikipedia.org/wiki/Singular_value_decomposition</a></li>
<li><a href="http://public.lanl.gov/mewall/kluwer2002.html">http://public.lanl.gov/mewall/kluwer2002.html</a></li>
</ul></li>
<li>Korbell</li>
<li>Slope-One</li>
</ul>
<h3><a href="http://www.wired.com/techbiz/media/magazine/16-03/mf_netflix/?currentPage=all">This Psychologist Might Outsmart the Math Brains Competing for the Netflix Prize</a></h3>
<p>"Anchoring" がポイントだって. へー. そのほか BellKor への言及もあり. 
dimension reduction の話. そのへんは予習として読み直す. </p>
<h3>Forum</h3>
<ul>
<li><a href="http://www.netflixprize.com/community/viewforum.php?id=13">http://www.netflixprize.com/community/viewforum.php?id=13</a></li>
<li>TODO: 日記トップにブックマークとして登録</li>
<li><a href="http://www.financemarkets.co.uk/2007/03/09/behavioral-economics-a-primer/">http://www.financemarkets.co.uk/2007/03/09/behavioral-economics-a-primer/</a></li>
</ul>
<h3>Beharioval Economics</h3>
<p>Porter の手法に出てきた "Anchoring" について. </p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Behavioral_economics">Wikipedia:Behavioral Economics</a></li>
<li><a href="http://www.dangoldstein.com/dsn/archives/2005/04/what_is_behavio.html">http://www.dangoldstein.com/dsn/archives/2005/04/what_is_behavio.html</a></li>
<li><a href="http://gregmankiw.blogspot.com/2006/06/behavioral-economics.html">http://gregmankiw.blogspot.com/2006/06/behavioral-economics.html</a></li>
<li><a href="http://khurramnaik.com/blog/2007/03/07/behavioral-economics-a-primer/">http://khurramnaik.com/blog/2007/03/07/behavioral-economics-a-primer/</a></li>
<li><a href="http://blog.robwebb2k.com/2007/04/24/human-computation-game-design-and-behavioral-economics/">http://blog.robwebb2k.com/2007/04/24/human-computation-game-design-and-behavioral-economics/</a></li>
</ul>
<p>そのうち読もう. あんまし発散してもキリないのでしばらくやいいや... </p>
<h3><a href="http://www.shirky.com/herecomeseverybody/">Here Comes Everybody</a></h3>
<p>Clay Shirky でたー. ポイントで買っとこう.</p>
<h3><a href="http://diveintomark.org/archives/2007/01/21/wrongroom">Wrongroom</a></h3>
<p>会社で <a href="http://hogbaysoftware.com/products/writeroom">writeroom</a> を
試している人をみて思いだした. 個人的にはまあ, 割とどうでもいい. 
そもそも自発的に集中してものを書くことってないし. 集中しちゃえば集中するし. 
Emacs で困ったことはないなあ. </p>
<h3>Bookmarker Isn't a Robot</h3>
<p>このページは知り合いには読んでもらっていいし, 
Google から迷いこんだ人が眺めるのもいい. 
上司がみつけて眉をしかめるのもいい. 
そういう空想がうかつな機密漏洩を抑止しているわけで. </p>
<p>でもブックマークされるのはいやだ. ほっといてくれ, とおもう. 杞憂だけれども. </p>
<p>読むのはいいがブックマークしないでほしい. そっとしておいてほしい. 
そういう感覚を理解しなかったり, 否定したりする人が一定数いるのは知っている. 
悲しい. ま, 世の中そういうもんだし, 捏造された attension が一過性なのが事実でもね. </p>
<h3>Netflix clips</h3>
<p>てきとうに forum からぐぐったもの。
Netflix 界隈では Simon Funk さんが SVD を使った人として有名らしい。
読んでない。</p>
<ul>
<li><a href="http://www.kdd.org/explorations/issues/9-1-2007-06/simon-funk-explorations.pdf">Interview with Simon Funk</a></li>
<li><a href="http://sifter.org/~simon/journal/20061211.html">Netflix Update: Try This at Home</a></li>
<li><a href="http://www.jesperandersen.net/2007/06/svd-is-dead-long-live-svd.html">SVD is dead, long live SVD</a></li>
</ul>
<p>ほかの参加者のページ. リンク集あり. みんな勉強したんだなと. </p>
<ul>
<li><a href="http://www.erikshelley.com/netflix/">Netflix Prize</a></li>
</ul>
<h3>Model Based Algorithms</h3>
<p>ぜんぜんわからん. 
わかんないのはデータマイニングがわかってないからだな.</p>
<p>まあクラスタはいいとして, 回帰問題, Horting がわからん. 
でも Horting がグラフの構造を使うというところまではわかった. </p>
<p>あとはキーワードだけメモしておこう: クラス分類問題, 順序回帰問題. </p>
<h4>確率モデル</h4>
<p>ひきつづきよくわからんが, ベイジアンがこの分類だというのはわかった. 
他のキーワード: 共起型, pLSI, ブースティング, 時系列モデル. </p>
<p>網羅的なのはいいけど優劣がぜんぜんわかんない...
Simen では速くてシンプルを優先, 精度はまあ, そこそこを目指そう. 
そういう意味では Netflix を優先的にあたるのが良いだろうね. </p>
<p>勉強すべきこと:</p>
<ul>
<li>SVD</li>
<li>KorBell のアルゴリズム</li>
<li>回帰問題 (線形回帰)</li>
<li>ベイジアン概観 (実装はしないと思うけど, フレームワークでサポートできる余地は残したい.)</li>
<li>Recommendation 固有の話題以外は、おとなしく bishop の本を読むしかなさそう。結局・・・。</li>
</ul>
