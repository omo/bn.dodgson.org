---
title: "Stacked books"
date: 2008-04-27
published: false
---
<h3>Stacked books</h3>
<p>連休はすこし積読を片づけないとなー. 
上から順に二冊はなんとかしよう.</p>
<ul>
<li>Collective Intelligence</li>
<li>Programming WCF</li>
</ul>
<ul>
<li>Performance Solutions</li>
<li>C++ の設計と進化</li>
<li>コンサルタントの秘密</li>
</ul>
<ul>
<li>Massively Multiplayer Game Development</li>
<li>クルーグマンミクロ経済学</li>
</ul>
<h3>simen</h3>
<p>コレクションの下地ができた. 単なる bdb のラッパだけど. 
なんかアルゴリズムを実装しよう. いちばん素朴なやつ. </p>
<h3>data size</h3>
<p>しかし考えてみると, 結構なサイズまでオンメモリでいけるよな. 
ユーザ数が 1M いても, node のサイズが 30B なら 30MB. ID だけ持っておくなら 8B で 8MB. 
simen のターゲットは 100K くらいまでだから, まあ楽勝. 
アイテム数. 
<a href="http://internet.watch.impress.co.jp/cda/news/2005/11/01/9705.html">amazon</a>
ですら 10M 強. (ユーザは 50M か. すげー.) 
<a href="http://www.rakuten.co.jp/">楽天</a> 
は 22M. 10M なら 300MB. さすがにでかい. ID だけなら 8MB. 
(商品の感想は 15M か. すくない...)</p>
<p>つまり node ID をオンメモリに載せるのは OK. </p>
<p>edge ID のサイズはわからんけど, グラフの密度が 0.1% でも 10M*10M*0.001 = 1G. 
しんどい. でも 0.1% てことはユーザが平均 1000 点買うってことか. 
見積りとしては厳しい気もする. 実際はその 1/10 - 1/100 くらい, 10M - 100M ってとこかな. 
基本は保守的にディスクを使い, オンメモリに持つオプションを用意するくらいかもね. 
その向きならコレクションの裏に隠せるからいいや. </p>
<p>こうしてみると <a href="http://www.grouplens.org/node/73">movielens dataset</a> は謎だ. 
1M/(3900*6040) = 0.04. 平均ひとり 200 件近く rate してるのか. 
コミュニティの性質によって差が大きいってこったな. </p>
<p>そもそもグラフの密度という指標はよくない気がしてきた. 規模に依存しすぎる. 
ユーザの平均次数を類推する方がよかろう. </p>
<p>amazon でみると, 自分は年平均 15 冊弱 x 8 年だから 100 冊. 
リアル本屋を使わない人なら 5 倍くらいで 500 冊. 1K とする. 50M*1K = 50G か. 
さっきと同じでかなり保守的だけど. </p>
<p>50G だとメモリに載っても一台じゃ時間がかかりすぎるからマシンをわける. 
マシンをわけるとメモリに載るだろう. 
と考えるとオンメモリ + マシン分散が王道ってことなんだろうなー. 
計算速度が bottleneck てことか. んー. </p>
<p>追記: 50GB の edge を保持すると 20B だとして 1000GB = 1TB. 
分散してもメモリにのせるのは辛そう. (100 台使っても一台 1GB.) 
やっぱり二次記憶を使うという直感は正しかった. 
見積りが保守的だから, ほんとは微妙なラインなんだろうけどね. </p>
<h3>scale goal</h3>
<p>simen は当面スケーラビリティを捨てて一台で扱える範囲を最大化する方針をとりたい. 
分散なんてやりかたわからんから目標として現実的でない. 
hosting で動かしたり DB サーバに寄生することを考えて, 10MB - 1GB の主記憶を使えるとする. </p>
<p>仮に item も user も 1M を上限として考える. 
node ID の保持に必要な主記憶が 1M*8B = 8MB. 10MB として, ふたつで 20MB. 
edge の数は user あたり平均 1K として, 1M*1K = 1G. 
edge が 30B だと 30GB. 当然メモリに載らん. </p>
<p>あとは correlation もどこかに持っておく必要があって, 
素朴に item-item で保存すると 1M*1M = 1T で論外. 
O(N^2) で計算しては捨てるか, kNN cache をするか. 
まあ cache だろうな. node あたり 1K くらい cache して 1K*1M = 1G. 
これもアホみたいに保守的な見積だから悩ましい. 
でも考えてみればだいたい edge と同じようなもんだよな. ディスクは要りそう. </p>
<p>結論: </p>
<ul>
<li>node id はメモリ</li>
<li>edge はディスク</li>
<li>node 単位の edge はメモリ</li>
<li>correlation cache はディスク</li>
</ul>
<p>当初の直感は正しかったけど, 計算したので安心した. </p>
<p>オンライン商店の商品件数に関する統計が欲しいなあ. 
白書とかに載ってるんだろうか. 本屋で探してみよう.
楽天でわかればいいんだけどね. </p>
<p>楽天は <a href="http://webservice.rakuten.co.jp/api/itemsearch/">API</a> があるのか. 
こいつでちょっと叩けばわかりそうだな. 呼出も一秒一回まで. けっこう寛容.</p>
<h3>nicovideo</h3>
<p>動画 1M. 再生 4T. ユーザ 5M. ケタはずれすぎる...</p>
<h3>simen: 1771 lines</h3>
<ul>
<li>ストレージ API 修正中<ul>
<li>アルゴリズムに着手しかけて間違いに気付く</li>
</ul></li>
</ul>
